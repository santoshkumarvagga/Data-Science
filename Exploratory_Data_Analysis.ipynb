{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Very Imp Step.\n",
    "\n",
    "EDA : Exploratory Data Analysis, How does one explore data with the aim of analysing it.\n",
    "\n",
    "Objectives of EDA:\n",
    "\n",
    "* Trying to understand data much better so that we can get an handle around it.\n",
    "* TO try and see if the data has some intresting patterns(which may or may not be helpful for client), But EDA is about uncovering those.\n",
    "\n",
    "Steps of EDA:\n",
    "\n",
    "1) Data Sourcing : Process of Finding/Loading the data into your system.\n",
    "2) Data Cleansing : Clearing common issues like Encoding issues, repeated names but with different spells, Marks = 0, etc. Make such mistakes to follow a consistent naming. \n",
    "3) Univariate Analysis : If we consider only one variable (column) and analyse how it affected the random variable(variable of interest)\n",
    "4) Bivariate Analysis: If we consider two varibale (columns) and anlayse their dependency on random variable.\n",
    "5) Derived Metrics : Creating new columns from available data (columns) that could help in analysis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1) Data Sourcing: Getting(Sources) Data and Loading it.\n",
    "\n",
    "For any Problem on Analytics, Basic thing required is Historical Data.\n",
    "\n",
    "2 types of Data:\n",
    "a) Public b) Private\n",
    "\n",
    "a) Public: Easy to get, but often dont contain info we are intrested in, most of times.\n",
    "b) Private: Hard to get (from offical agencies, govt), contain useful data, most of times.\n",
    "\n",
    "* Public data sourcing: We can get from Internet Browsing for free of cost. Eg: awesome-public-datasets\n",
    "\n",
    "    NOTE: Understanding of Domain is must to see what we can fecth from Data.\n",
    "\n",
    "* private Data Sourcing : we get it from respective organisations directly following all the protocol.May include Money, Officials permission. etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2) Data Cleaning: Once we have data, Clean it for data quality issues.\n",
    "\n",
    "* There are various types of data quality issues - formatting errors (e.g. rows and columns are ill-formatted, unclearly named etc.), missing values, repeated rows, spelling inconsistencies, etc. \n",
    "* These issues could make it difficult to analyse data and could lead to errors or irrelevant results. Thus, these issues need to be corrected before data is analysed.\n",
    "\n",
    "Data Cleaning steps:\n",
    "1) Fix rows and columns\n",
    "2) Fix missing values\n",
    "3) Standardise values\n",
    "4) Fix invalid values\n",
    "5) Filter data\n",
    "\n",
    "\n",
    "1)  Fix rows and columns: We keep only row/column values, not the headers, footers, sl.no, subtotal, etc\n",
    "    Refer this Checklist - https://drive.google.com/drive/folders/106ouzKgWWRrOfJwgSAQPINnU3Sc4BVyh\n",
    "\n",
    "2) Missing Values: Steps to deal with missing values are given below,\n",
    "* Set values as missing values: Identify values that indicate missing data, and yet are not recognised by the software as such, e.g treat blank strings, \"NA\", \"XX\", \"999\", etc. as missing.\n",
    "\n",
    "* Adding is good, exaggerating is bad: You should try to get information from reliable external sources as much as possible, but if you can’t, then it is better to keep missing values as such rather than exaggerating the existing rows/columns.\n",
    "\n",
    "* Delete rows, columns: Rows could be deleted if the number of missing values are significant in number, as this would not impact the analysis. Columns could be removed if the missing values are quite significant in number.\n",
    "\n",
    "* Fill partial missing values using business judgement: Missing time zone, century, etc. These values are easily identifiable.\n",
    "\n",
    "3) Standaridise Values: We have come to cell level. Convert all cells of a column to same unit(KMPH or Metres)\n",
    "    2 Types: \n",
    "\n",
    "        a) Standaridising Variables(numeic): steps to deal with are,\n",
    "\n",
    "            * Standardise units: Ensure all observations under a variable have a common and consistent unit, e.g. convert lbs to kgs,               miles/hr to km/hr, etc.\n",
    "\n",
    "            * Scale values if required:  Make sure the observations under a variable have a common scale\n",
    "\n",
    "            * Standardise precision for better presentation of data, e.g. 4.5312341 kgs to 4.53 kgs.\n",
    "\n",
    "            * Remove outliers: Remove high and low values that would disproportionately affect the results of your analysis.\n",
    "\n",
    "\n",
    "        b) Standaridising Text: steps to dela with are:\n",
    "\n",
    "            * Remove extra characters like such as common prefix/suffix, leading/trailing/multiple spaces, etc. These are irrelevant                to analysis.\n",
    "\n",
    "            * Standardise case: There are various cases that string variables may take, e.g. UPPERCASE, lowercase, Title Case,                      Sentence case, etc.\n",
    "\n",
    "            * Standardise format: E.g. 23/10/16 to 2016/10/23, “Modi, Narendra\" to “Narendra Modi\", etc.\n",
    "\n",
    "        NOTE: Why Outlier treatment is important? https://www.kdnuggets.com/2017/02/removing-outliers-standard-deviation-python.html\n",
    "\n",
    "4) Invalid Values: steps to deal with,\n",
    "\n",
    "* Encode unicode properly: In case the data is being read as junk characters, try to change encoding, E.g. CP1252 instead of UTF-8.\n",
    "* Convert incorrect data types: Correct the incorrect data types to the correct data types for ease of analysis. E.g. if numeric values are stored as strings, it would not be possible to calculate metrics such as mean, median, etc. Some of the common data type corrections are — string to number: \"12,300\" to “12300”; string to date: \"2013-Aug\" to “2013/08”; number to string: “PIN Code 110001” to \"110001\"; etc.\n",
    "* Correct values that go beyond range: If some of the values are beyond logical range, e.g. temperature less than -273° C (0° K), you would need to correct them as required. A close look would help you check if there is scope for correction, or if the value needs to be removed.\n",
    "* Correct values not in the list: Remove values that don’t belong to a list. E.g. In a data set containing blood groups of individuals, strings “E” or “F” are invalid values and can be removed.\n",
    "* Correct wrong structure: Values that don’t follow a defined structure can be removed. E.g. In a data set containing pin codes of Indian cities, a pin code of 12 digits would be an invalid value and needs to be removed. Similarly, a phone number of 12 digits would be an invalid value.\n",
    "* Validate internal rules: If there are internal rules such as a date of a product’s delivery must definitely be after the date of the order, they should be correct and consistent.\n",
    "\n",
    "5) Filtering Data(for the ease of Analysis):\n",
    "\n",
    "* Deduplicate data: Remove identical rows, remove rows where some columns are identical\n",
    "* Filter rows: Filter by segment, filter by date period to get only the rows relevant to the analysis\n",
    "* Filter columns: Pick columns relevant to the analysis\n",
    "* Aggregate data: Group by required keys, aggregate the rest\n",
    "\n",
    "Once we get specific parts of data to analyse, we are ready get insights into by analysing. Lets look how to analyse."
   ]
  },
  {
   "source": [
    "2) Univariate Analysis: analysing variables one at a time. It is important to separately understand each variable before moving on to analysing multiple variables together.\n",
    "\n",
    "Mainly:\n",
    "    * Metadata description (Data Description)\n",
    "    * Data distribution plots\n",
    "    * Summary metrics\n",
    "\n",
    "1) Metadata: Given a dataset, Understand what it contains. Information about a data set can be gained by simply looking at its Metadata. \n",
    "    Hence, Metadata is the data that describes every variable in detail. Information like \n",
    "    a) Size of dataset\n",
    "    b) How and when the dataset was created \n",
    "    c) What the rows and variables represent, etc are captured in Metadata.\n",
    "\n",
    "Types of Variables: 2 types Mainly\n",
    "a) Categorical Variables (2 types)\n",
    "b) Quantitative\n",
    "\n",
    "a) Categorical Variables: Variables that have two or more categories. 2 types:\n",
    "    1) Ordered Categorical Variables: have intrinsic ordering among them. Ex: Level : High, Medium, Low; Qualification: Primary, PUC, Degree\n",
    "    2) Unordered Categorical Variables: dont have intrinsic ordering among them. Ex: Gender: Male, Female; Department: CSE, ECE, EEE\n",
    "\n",
    "\n",
    "b) Quantitative Variables: Varibales that can be added, subtracted, divided and Multiplied. Eg: a = 10, b= 30, c=b-a \n",
    "\n",
    "Univariate analysis of Unordered Categorical variables:\n",
    "\n",
    "* Plots are immensely helpful in identifying hidden patterns in the data \n",
    "* It is possible to extract meaningful insights from unordered categorical variables using rank-frequency plots\n",
    "* Rank-frequency plots of unordered categorical variables, when plotted on a log-log scale, typically result in a power law       distribution  \n",
    "\n",
    "Univariate analysis of Ordered Categorical variables:\n",
    "\n",
    "*  Whenever you have a continuous or an ordered categorical variable, make sure you plot a histogram or a bar chart and observe any unexpected trends in it.\n",
    "\n",
    "Univariate analysis of Quantitative Variables:\n",
    "Summary Metrics: Mean, Median, Mode, Standard Deviation, Inter-Quartile Range(75%-25%).\n",
    "\n",
    "* Mean and median are single values that broadly give a representation of the entire data. As Anand stated very clearly, it is very important to understand when to use these metrics to avoid doing inaccurate analysis.\n",
    "\n",
    "\n",
    "* While mean gives an average of all the values, median gives a typical value that could be used to represent the entire group. As a simple rule of thumb, always question someone if someone uses the mean, since median is almost always a better measure of ‘representativeness’.\n",
    "\n",
    "* Standard deviation and interquartile difference are both used to represent the spread of the data.\n",
    "\n",
    "* Interquartile difference is a much better metric than standard deviation if there are outliers in the data. This is because the standard deviation will be influenced by outliers while the interquartile difference will simply ignore them.\n",
    "\n",
    "* box plots are used to understand the spread of data.\n",
    "-----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Summary of Univariate Variable Analysis:\n",
    "\n",
    "* Metadata description describes the data in a structured way. You should make it a habit of creating a metadata description for whatever data set you are working on. Not only will it serve as a reference point for you, it will also help other people understand the data better and save time.\n",
    "\n",
    "* Distribution plots reveal interesting insights about the data. You can observe various visible patterns in the plots and try to understand how they came to be.\n",
    "\n",
    "* Summary metrics are used to obtain a quantitative summary of the data. Not all metrics can be used everywhere. Thus, it is important to understand the data and then choose what metric to use to summarise the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2) Segmented univariate analysis:\n",
    "* Though the simple univariate analysis is tremendously useful in many cases, the real strength of univariate analysis often lies in segmented univariate analysis.\n",
    "* We will extend univariate analysis and learn to conduct univariate analysis across ‘segments’\n",
    "\n",
    "Mainly:\n",
    "-------\n",
    "1) Basis of segmentation\n",
    "2) Comparison of averages\n",
    "3) Comparison of other metrics\n",
    "\n",
    "** In segmented univariate analysis, we segment the categorical variables and then conduct univariate analysis across its categories. Let’s see how this simple technique can help you unveil powerful insights.\n",
    "\n",
    "The entire segmentation process can be divided into four parts:\n",
    "\n",
    "* Take raw data\n",
    "* Group by dimensions\n",
    "* Summarise using a relevant metric such as mean, median, etc.\n",
    "* Compare the aggregated metric across groups/categories\n",
    "\n",
    "But what if you have a large number of variables in your dataset. It looks very repetitive task to perform the same analysis on the large bunch of variables. One way of solving this problem is to make a table with the categorical variables on one axis and the numeric variables (or measures/facts) on the other\n",
    "\n",
    "Once you are done with segmentation, the next step is to compare your results within the category. You can either compare the means, or you can go for other descriptive statistics such as median, max, min, etc. \n",
    "\n",
    "\n",
    "** segmented univariate analysis — the comparison of averages:\n",
    "TIP 1: \n",
    "“Don’t blindly believe in the averages of the buckets — you need to observe the distribution of each bucket closely and ask yourself if the difference in means is significant enough to draw a conclusion. If the difference in means is small, you may not be able to draw inferences. In such cases, a technique called hypothesis testing is used to ascertain whether the difference in means is significant or due to randomness.“ Don’t worry if you do not get the concept of hypothesis correctly, It will be dealt separately in hypothesis module.\n",
    "\n",
    "** Compare metrics other than the mean:\n",
    "Once you have identified the variables based on the business problem for analysing the segments, the next step is to know the distribution of segments and compare the average of each segment. But this is not the only way of comparing segments. There are various metrics which you can use to understand and explain your data easily.\n",
    "\n",
    "Plot Box Plots of all Categories of the Variable and see insights.\n",
    "\n",
    "Besides finding the segments and comparing the metrics, your primary focus should be on understanding the results arising from the segments.\n",
    "\n",
    "So, this is all about analysing the variables one at a time. But what if you want to analyse more than one variable at the same time? How would you find the relationship between two variables? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2) Bivariate Analysis:\n",
    "In univariate analysis, you learnt:\n",
    "* How to get insights from distribution of individual variables \n",
    "* How to observe the effect of various categorical variables on target variables such as an impact on maths percentage by father's education or mother's education.\n",
    "\n",
    "Now, understand the ‘relationship between two variables’, which is called Bivariate Analysis. You will learn the following topics:\n",
    "1) Bivariate analysis on continuous variables\n",
    "2) Bivariate analysis on categorical variables\n",
    "\n",
    "1) Bivariate Analysis on Continuous Variables:\n",
    "Take two continous variables, and try to identify the correaltion(-1.0 to 1.0) between them using Scatterplot.\n",
    "If in the Scatterplot, (Try to draw best possible line).\n",
    "The points are pointing downwards, It is Negative correlation(-1) Saying if one increases, other decreases by some factor\n",
    "The points are pointing upwards, It is Positive Correlation(+1) Saying if one increases, other also increases by some factor\n",
    "and \n",
    "The closeness of points to the line is the measure how well are these corelated.\n",
    "\n",
    "If there is no correlation among points in Scaltterplot, it means Neutral corelation(0). Points are very far from each other.\n",
    "\n",
    "To summarise, correlation is a number between -1 and 1 which quantifies the extent to which two variables ‘correlate’ with each other.\n",
    "If one increases as the other increases, the correlation is positive\n",
    "If one decreases as the other increases, the correlation is negative\n",
    "If one stays constant as the other varies, the correlation is zero\n",
    "\n",
    "In general, a positive correlation means that two variables will increase together and decrease together, e.g. an increase in rain is accompanied by an increase in humidity. A negative correlation means that if one variable increases the other decreases, e.g. in some cases, as the price of a commodity decreases its demand increases.\n",
    "\n",
    "A perfect positive correlation means that the correlation coefficient is exactly 1. This implies that as one variable moves, either up or down, the other one moves in the same direction. A perfect negative correlation means that two variables move in opposite directions, while a zero correlation implies no relationship at all. \n",
    "\n",
    "\n",
    "So now, you have an idea of how correlation is useful for deriving useful insights from continuous variables. Usage of correlation is widely prevalent in industry nowadays, and there are various challenges faced by organisations when it comes to representing the way of calculating the correlation for a large number of variables at a time. And this is what you will learn in the next lecture — basically how industries solve business problems just by using correlation analysis.\n",
    "\n",
    "Correlation Matrix - helps to identify corelation coefficient between variables(more than two)\n",
    "\n",
    "* How to find the relationship between pairs of categorical variables and the relationship between categorical and continuous variables.?\n",
    "\n",
    "Bivariate Analysis on categorical variables:\n",
    "(how to quantify and understand the relationship between pairs of categorical and continuous variables.)\n",
    "\n",
    "The categorical bivariate analysis is essentially an extension of the segmented univariate analysis to another categorical variable. In segmented univariate analysis, you compare metrics such as ‘mean of X’ across various segments of a categorical variable, e.g. mean marks of a student are higher for ‘degree and above’ than other levels of the mother’s education; or the median income of educated parents is higher than that of uneducated ones, etc.\n",
    "\n",
    " \n",
    "\n",
    "In the categorical bivariate analysis, you extend this comparison to other categorical variables and ask — is this true for all categories of another variable, say, men and women? Take another categorical variable, such as state, and ask — is the median income of educated parents higher than that of uneducated ones in all states?\n",
    "\n",
    " \n",
    "\n",
    "Thus, you are drilling down into another categorical variable and getting closer to the true patterns in the data. In fact, you may also go to the next level and ask — is the median income of educated parents higher than that of uneducated ones (variable 1)  in all states (variable 2) for all age groups (variable 3)? This is what you may call ‘trivariate analysis’, and though it gives you a more granular version of the truth, it gets a bit complex to make sense of and explain to others (and hence it is not usually done in EDA).\n",
    "\n",
    "Thus, remember that doing only conducting segmented univariate analysis may deceive you into thinking that a certain phenomenon is true without asking the question — is it true for all sub-populations or is it true only when you aggregate information across the entire population?\n",
    "\n",
    " \n",
    "\n",
    "So in general, there are two fundamental aspects of analysing categorical variables:\n",
    "\n",
    "1) To see the distribution of two categorical variables. For example, if you want to compare the number of boys and girls who play games, you can make a ‘cross table’ as given below:\n",
    "\n",
    "2) To see the distribution of two categorical variables with one continuous variable. For example, you saw how a student’s percentage in science is distributed based on the father’s occupation (categorical variable 1) and the poverty level (categorical variable 2).\n",
    "\n",
    "\n",
    "Usually, you do not analyse more than two variables at a time, though there are ways to do that. Machine learning models are essentially a way to do that, some of which you will learn in the next course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Derived Metrics:\n",
    "\n",
    "How to create new variables using existing ones and get meaningful information by analysing them. In other words, we will discuss some methods to derive new metrics from the existing ones. The agenda for the session is as follows:\n",
    "\n",
    "1) Type-driven metrics\n",
    "2) Business-driven metrics\n",
    "3) Data-driven metrics\n",
    "\n",
    "\n",
    "Sometimes, you would not get the most valuable insights by analysing the data available to you. You often need to create new variables using the existing ones to get meaningful insights.\n",
    "\n",
    "\n",
    "New variables could be created based on your business understanding or they can be suggested by your clients. Let’s understand how business understanding plays an important role in deriving new variables.\n",
    "\n",
    "1) Type-Driven Variables: 2 types\n",
    "        a) stevens topology\n",
    "        b) Latitude and Longitude\n",
    "\n",
    "    Steven’s typology classifies variables into four types — nominal, ordinal, interval and ratio:\n",
    "\n",
    "Nominal variables: Categorical variables, where the categories differ only by their names; there is no order among categories, e.g. colour (red, blue, green), gender (male, female), department (HR, analytics, sales)\n",
    "\n",
    "These are the most basic form of categorical variables\n",
    "\n",
    "Ordinal variables: Categories follow a certain order, but the mathematical difference between categories is not meaningful, e.g. education level (primary school, high school, college), height (high, medium, low), performance (bad, good, excellent), etc.\n",
    "\n",
    "Ordinal variables are nominal as well\n",
    "\n",
    "Interval variables: Categories follow a certain order, and the mathematical difference between categories is meaningful but division or multiplication is not, e.g. temperature in degrees celsius ( the difference between 40 and 30 degrees C is meaningful, but 30 degrees x 40 degrees is not), dates (the difference between two dates is the number of days between them, but 25th May / 5th June is meaningless), etc.\n",
    "\n",
    "Interval variables are both nominal and ordinal\n",
    "\n",
    "Ratio variables: Apart from the mathematical difference, the ratio (division/multiplication) is possible, e.g. sales in dollars ($100 is twice $50), marks of students (50 is half of 100), etc.\n",
    "\n",
    "Ratio variables are nominal, ordinal and interval type\n",
    "\n",
    "Understanding types of variables enables you to derive new metrics of types different from the same column.\n",
    "\n",
    "For example, age in years is a ratio attribute, but you can convert it into an ordinal type by binning it into categories such as children (< 13 years), teenagers (13-19 years), young adults (20-25 years), etc. This enables you to ask questions, e.g. do teenagers do X better than children, are young adults more likely to do X than the other two types, etc. Here, X is an action you are interested in measuring. \n",
    "\n",
    "2) Business-driven Metrics:\n",
    "\n",
    "So far, you've learnt how to extract meaningful information from existing variables, e.g. extracting a \"month\" variable from the date variable. But what if you want to extract information that requires business expertise? For example, if you wish to know which students passed based on a list of scores in an exam, you need to know the criteria for passing the exam.\n",
    "\n",
    "Deriving metrics from the business perspective is not an easy task. It requires a decent domain experience. Without understanding the domain correctly, deriving insights becomes difficult and prone to errors. \n",
    "\n",
    "3) Data Driven Metrics:\n",
    "Let see how the data-driven metrics can be created from existing data.\n",
    "\n",
    "To summarise, data-driven metrics can be created based on the variables present in the existing data set. For example, if you have two variables in your data set such as \"weight\" and \"height\" which shows a high correlation. So, instead of analysing \"weight\" and \"height\" variables separately, you can think of deriving a new metric \"Body Mass Index (BMI)\". Once you get the BMI, you can easily categorise people based on their fitness, e.g. a BMI below 18.5 should be considered as an underweight category, while BMI above 30.0 is considered as obese, by standard norms. This is how data-driven metrics can help you discover hidden patterns out of the data."
   ]
  }
 ]
}